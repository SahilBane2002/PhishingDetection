{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTVY5lz4vJQM"
   },
   "source": [
    "# **Phishing Website Detection by Machine Learning Techniques**\n",
    "\n",
    "*Final project of AI & Cybersecurity Course*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_cJA-yD-vNcS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOq598WCqIol"
   },
   "source": [
    "## **2. Loading Data:**\n",
    "\n",
    "The features are extracted and store in the csv file. The working of this can be seen in the 'Phishing Website Detection_Feature Extraction.ipynb' file.\n",
    "\n",
    "The reulted csv file is uploaded to this notebook and stored in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "C297HhYulXcb",
    "outputId": "d6e2a9df-586e-4192-b8ec-1e7b7025c0c3"
   },
   "outputs": [],
   "source": [
    "#importing basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "fVPglpaf4REa",
    "outputId": "eef4a4ca-e12d-4cd3-e011-20376fc752a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Have_IP</th>\n",
       "      <th>Have_At</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>URL_Depth</th>\n",
       "      <th>Redirection</th>\n",
       "      <th>https_Domain</th>\n",
       "      <th>TinyURL</th>\n",
       "      <th>Prefix/Suffix</th>\n",
       "      <th>DNS_Record</th>\n",
       "      <th>Web_Traffic</th>\n",
       "      <th>Domain_Age</th>\n",
       "      <th>Domain_End</th>\n",
       "      <th>iFrame</th>\n",
       "      <th>Mouse_Over</th>\n",
       "      <th>Right_Click</th>\n",
       "      <th>Web_Forwards</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graphicriver.net</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ecnavi.jp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hubpages.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extratorrent.cc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>icicibank.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Domain  Have_IP  Have_At  URL_Length  URL_Depth  Redirection  \\\n",
       "0  graphicriver.net        0        0           1          1            0   \n",
       "1         ecnavi.jp        0        0           1          1            1   \n",
       "2      hubpages.com        0        0           1          1            0   \n",
       "3   extratorrent.cc        0        0           1          3            0   \n",
       "4     icicibank.com        0        0           1          3            0   \n",
       "\n",
       "   https_Domain  TinyURL  Prefix/Suffix  DNS_Record  Web_Traffic  Domain_Age  \\\n",
       "0             0        0              0           0            1           1   \n",
       "1             0        0              0           0            1           1   \n",
       "2             0        0              0           0            1           0   \n",
       "3             0        0              0           0            1           0   \n",
       "4             0        0              0           0            1           0   \n",
       "\n",
       "   Domain_End  iFrame  Mouse_Over  Right_Click  Web_Forwards  Label  \n",
       "0           1       0           0            1             0      0  \n",
       "1           1       0           0            1             0      0  \n",
       "2           1       0           0            1             0      0  \n",
       "3           1       0           0            1             0      0  \n",
       "4           1       0           0            1             0      0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the data\n",
    "data0 = pd.read_csv('DataFiles/5.urldata.csv')\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMXihulvMcAj"
   },
   "source": [
    "## **3. Familiarizing with Data**\n",
    "In this step, few dataframe methods are used to look into the data and its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "4hARIXyGKorc",
    "outputId": "bc223e7f-4529-4ebe-e7d0-7eef13e691c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 18)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of the dataset\n",
    "data0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "Q3uBm9ObMyaG",
    "outputId": "551b4c2e-8b33-4a6a-c3e9-f168066915de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Domain', 'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth',\n",
       "       'Redirection', 'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record',\n",
       "       'Web_Traffic', 'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over',\n",
       "       'Right_Click', 'Web_Forwards', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing the features of the dataset\n",
    "data0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "id": "gBMqupCMM74V",
    "outputId": "0e530eb9-699d-4ece-800d-8e853fc9d6ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Domain         10000 non-null  object\n",
      " 1   Have_IP        10000 non-null  int64 \n",
      " 2   Have_At        10000 non-null  int64 \n",
      " 3   URL_Length     10000 non-null  int64 \n",
      " 4   URL_Depth      10000 non-null  int64 \n",
      " 5   Redirection    10000 non-null  int64 \n",
      " 6   https_Domain   10000 non-null  int64 \n",
      " 7   TinyURL        10000 non-null  int64 \n",
      " 8   Prefix/Suffix  10000 non-null  int64 \n",
      " 9   DNS_Record     10000 non-null  int64 \n",
      " 10  Web_Traffic    10000 non-null  int64 \n",
      " 11  Domain_Age     10000 non-null  int64 \n",
      " 12  Domain_End     10000 non-null  int64 \n",
      " 13  iFrame         10000 non-null  int64 \n",
      " 14  Mouse_Over     10000 non-null  int64 \n",
      " 15  Right_Click    10000 non-null  int64 \n",
      " 16  Web_Forwards   10000 non-null  int64 \n",
      " 17  Label          10000 non-null  int64 \n",
      "dtypes: int64(17), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Information about the dataset\n",
    "data0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfrxhE3pNfiw"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "colab_type": "code",
    "id": "N9K0yAdAM70w",
    "outputId": "05687b93-945e-4fee-c3da-baae065ad528"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "colab_type": "code",
    "id": "jy9fjgj3M7zc",
    "outputId": "0292cc0a-8436-49d9-c724-ad9345f1b693"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cbVPMe8NxFN"
   },
   "source": [
    "## **5. Data Preprocessing & EDA**\n",
    "Here, we clean the data by applying data preprocesssing techniques and transform the data to use it in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "id": "b_HKPelgnmf8",
    "outputId": "f9fb9a1b-0ddc-470a-f4c0-db248a1a94f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Have_IP</th>\n",
       "      <th>Have_At</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>URL_Depth</th>\n",
       "      <th>Redirection</th>\n",
       "      <th>https_Domain</th>\n",
       "      <th>TinyURL</th>\n",
       "      <th>Prefix/Suffix</th>\n",
       "      <th>DNS_Record</th>\n",
       "      <th>Web_Traffic</th>\n",
       "      <th>Domain_Age</th>\n",
       "      <th>Domain_End</th>\n",
       "      <th>iFrame</th>\n",
       "      <th>Mouse_Over</th>\n",
       "      <th>Right_Click</th>\n",
       "      <th>Web_Forwards</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.773400</td>\n",
       "      <td>3.072000</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.845700</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.8099</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.06660</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.073961</td>\n",
       "      <td>0.148632</td>\n",
       "      <td>0.418653</td>\n",
       "      <td>2.128631</td>\n",
       "      <td>0.115408</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.286625</td>\n",
       "      <td>0.290727</td>\n",
       "      <td>0.301079</td>\n",
       "      <td>0.361254</td>\n",
       "      <td>0.492521</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>0.287481</td>\n",
       "      <td>0.24934</td>\n",
       "      <td>0.02645</td>\n",
       "      <td>0.306955</td>\n",
       "      <td>0.500025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Have_IP       Have_At    URL_Length     URL_Depth   Redirection  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.005500      0.022600      0.773400      3.072000      0.013500   \n",
       "std        0.073961      0.148632      0.418653      2.128631      0.115408   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      1.000000      2.000000      0.000000   \n",
       "50%        0.000000      0.000000      1.000000      3.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      4.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000     20.000000      1.000000   \n",
       "\n",
       "       https_Domain       TinyURL  Prefix/Suffix    DNS_Record   Web_Traffic  \\\n",
       "count  10000.000000  10000.000000   10000.000000  10000.000000  10000.000000   \n",
       "mean       0.000200      0.090300       0.093200      0.100800      0.845700   \n",
       "std        0.014141      0.286625       0.290727      0.301079      0.361254   \n",
       "min        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000       0.000000      0.000000      1.000000   \n",
       "50%        0.000000      0.000000       0.000000      0.000000      1.000000   \n",
       "75%        0.000000      0.000000       0.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "         Domain_Age  Domain_End        iFrame   Mouse_Over  Right_Click  \\\n",
       "count  10000.000000  10000.0000  10000.000000  10000.00000  10000.00000   \n",
       "mean       0.413700      0.8099      0.090900      0.06660      0.99930   \n",
       "std        0.492521      0.3924      0.287481      0.24934      0.02645   \n",
       "min        0.000000      0.0000      0.000000      0.00000      0.00000   \n",
       "25%        0.000000      1.0000      0.000000      0.00000      1.00000   \n",
       "50%        0.000000      1.0000      0.000000      0.00000      1.00000   \n",
       "75%        1.000000      1.0000      0.000000      0.00000      1.00000   \n",
       "max        1.000000      1.0000      1.000000      1.00000      1.00000   \n",
       "\n",
       "       Web_Forwards         Label  \n",
       "count  10000.000000  10000.000000  \n",
       "mean       0.105300      0.500000  \n",
       "std        0.306955      0.500025  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.500000  \n",
       "75%        0.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBqTcpqen_fB"
   },
   "source": [
    "The above obtained result shows that the most of the data is made of 0's & 1's except 'Domain' & 'URL_Depth' columns. The Domain column doesnt have any significance to the machine learning model training. So dropping the *'Domain'* column from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tdpRw0Bcn_K1"
   },
   "outputs": [],
   "source": [
    "#Dropping the Domain column\n",
    "data = data0.drop(['Domain'], axis = 1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peN2Q-WdowNL"
   },
   "source": [
    "This leaves us with 16 features & a target column. The *'URL_Depth'* maximum value is 20. According to my understanding, there is no necessity to change this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "iGO3nWV1nvW1",
    "outputId": "f9cc1bae-b91b-483d-a1ca-44aea204dae5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Have_IP          0\n",
       "Have_At          0\n",
       "URL_Length       0\n",
       "URL_Depth        0\n",
       "Redirection      0\n",
       "https_Domain     0\n",
       "TinyURL          0\n",
       "Prefix/Suffix    0\n",
       "DNS_Record       0\n",
       "Web_Traffic      0\n",
       "Domain_Age       0\n",
       "Domain_End       0\n",
       "iFrame           0\n",
       "Mouse_Over       0\n",
       "Right_Click      0\n",
       "Web_Forwards     0\n",
       "Label            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#checking the data for null or missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xo6cAqAqJOq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "4LZnaoU_qBsz",
    "outputId": "df212692-ea66-4d67-a4aa-00a256010f69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Have_IP</th>\n",
       "      <th>Have_At</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>URL_Depth</th>\n",
       "      <th>Redirection</th>\n",
       "      <th>https_Domain</th>\n",
       "      <th>TinyURL</th>\n",
       "      <th>Prefix/Suffix</th>\n",
       "      <th>DNS_Record</th>\n",
       "      <th>Web_Traffic</th>\n",
       "      <th>Domain_Age</th>\n",
       "      <th>Domain_End</th>\n",
       "      <th>iFrame</th>\n",
       "      <th>Mouse_Over</th>\n",
       "      <th>Right_Click</th>\n",
       "      <th>Web_Forwards</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Have_IP  Have_At  URL_Length  URL_Depth  Redirection  https_Domain  \\\n",
       "0        0        0           1          8            0             0   \n",
       "1        0        0           1          2            0             0   \n",
       "2        0        0           1          3            0             0   \n",
       "3        0        0           0          2            0             0   \n",
       "4        0        0           1          4            0             0   \n",
       "\n",
       "   TinyURL  Prefix/Suffix  DNS_Record  Web_Traffic  Domain_Age  Domain_End  \\\n",
       "0        1              0           1            1           1           1   \n",
       "1        0              1           0            1           1           1   \n",
       "2        0              0           0            1           0           1   \n",
       "3        0              0           0            1           0           0   \n",
       "4        0              0           0            0           0           1   \n",
       "\n",
       "   iFrame  Mouse_Over  Right_Click  Web_Forwards  Label  \n",
       "0       0           0            1             0      1  \n",
       "1       0           0            1             0      1  \n",
       "2       0           0            1             0      1  \n",
       "3       0           0            1             0      1  \n",
       "4       0           0            1             0      0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FsQosd_nycx"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fs5hu2UR4SIF"
   },
   "source": [
    "## **6. Splitting the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "FzEU-wcLN8K7",
    "outputId": "534f9839-31e6-4b19-b469-c16db57fd5a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 16), (10000,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sepratating & assigning features and target columns to X & y\n",
    "y = data['Label']\n",
    "X = data.drop('Label',axis=1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "84xKobSqAV3U",
    "outputId": "20c0a9f7-d20e-4176-f815-238727c44336"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 16), (2000, 16))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into train and test sets: 80-20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ah9B035xOjs1"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5Tg_ei0-xPU"
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPBHdBikSXHv"
   },
   "outputs": [],
   "source": [
    "# Creating holders to store the model performance results\n",
    "ML_Model = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "\n",
    "#function to call for storing the results\n",
    "def storeResults(model, a,b):\n",
    "  ML_Model.append(model)\n",
    "  acc_train.append(round(a, 3))\n",
    "  acc_test.append(round(b, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwQ8DP4OsmcG"
   },
   "source": [
    "**PSO ALGORTIHM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "7cy28vy3fDab",
    "outputId": "2947530e-ed77-40b2-bc9e-c3c575ff4faf"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, fitness, dim, min_bounds, max_bounds, seed):\n",
    "        self.rnd = random.Random(seed)\n",
    "        self.position = [0.0 for _ in range(dim)]\n",
    "        self.velocity = [0.0 for _ in range(dim)]\n",
    "        self.best_part_pos = [0.0 for _ in range(dim)]\n",
    "        \n",
    "        for i in range(dim):\n",
    "            self.position[i] = (max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i]\n",
    "            self.velocity[i] = (max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i]\n",
    "        \n",
    "        self.fitness = fitness(self.position)\n",
    "        self.best_part_pos = copy.copy(self.position)\n",
    "        self.best_part_fitnessVal = self.fitness\n",
    "\n",
    "def pso(fitness, max_iter, n, dim, min_bounds, max_bounds):\n",
    "    w = 0.729\n",
    "    c1 = 1.49445\n",
    "    c2 = 1.49445\n",
    "    rnd = random.Random(0)\n",
    "    print(\"min_bounds:\", min_bounds)  # Add this line to print min_bounds\n",
    "    print(\"max_bounds:\", max_bounds)\n",
    "    \n",
    "    swarm = [Particle(fitness, dim, min_bounds, max_bounds, i) for i in range(n)]\n",
    "    \n",
    "    best_swarm_pos = [0.0 for _ in range(dim)]\n",
    "    best_swarm_fitnessVal = sys.float_info.max\n",
    "    w_values = []\n",
    "    for i in range(n):\n",
    "        if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "            best_swarm_fitnessVal = swarm[i].fitness\n",
    "            best_swarm_pos = copy.copy(swarm[i].position)\n",
    "    \n",
    "    Iter = 0\n",
    "    results = []  # Store results for writing to Excel\n",
    "    \n",
    "    while Iter < max_iter:\n",
    "        if Iter % 10 == 0 and Iter > 1:\n",
    "            print(\"Iter = \" + str(Iter) + \" best fitness = %.3f\" % best_swarm_fitnessVal)\n",
    "            results.append((Iter, best_swarm_fitnessVal))\n",
    "            w_values.append(w)\n",
    "        for i in range(n):\n",
    "            for k in range(dim):\n",
    "                r1 = rnd.random()\n",
    "                r2 = rnd.random()\n",
    "                swarm[i].velocity[k] = (\n",
    "                    (w *swarm[i].velocity[k]) +\n",
    "                    (c1 * r1 * (swarm[i].best_part_pos[k] - swarm[i].position[k])) +\n",
    "                    (c2 * r2 *(best_swarm_pos[k] - swarm[i].position[k]))\n",
    "                )\n",
    "                if swarm[i].velocity[k] < min_bounds[k]:\n",
    "                    swarm[i].velocity[k] = min_bounds[k]\n",
    "                elif swarm[i].velocity[k] > max_bounds[k]:\n",
    "                    swarm[i].velocity[k] = max_bounds[k]\n",
    "            for k in range(dim):\n",
    "                swarm[i].position[k] += swarm[i].velocity[k]\n",
    "            swarm[i].fitness = fitness(swarm[i].position)\n",
    "            if swarm[i].fitness < swarm[i].best_part_fitnessVal:\n",
    "                swarm[i].best_part_fitnessVal = swarm[i].fitness\n",
    "                swarm[i].best_part_pos = copy.copy(swarm[i].position)\n",
    "            if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "                best_swarm_fitnessVal = swarm[i].fitness\n",
    "                best_swarm_pos = copy.copy(swarm[i].position)\n",
    "        Iter += 1\n",
    "    \n",
    "    \n",
    "\n",
    "    return best_swarm_pos\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PSO Using Exponential Map (only w_max)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 10 best fitness = 0.000\n",
      "Iter = 20 best fitness = 0.000\n",
      "Iter = 30 best fitness = 0.000\n",
      "Iter = 40 best fitness = 0.000\n",
      "Iter = 50 best fitness = 0.000\n",
      "Iter = 60 best fitness = 0.000\n",
      "Iter = 70 best fitness = 0.000\n",
      "Iter = 80 best fitness = 0.000\n",
      "Iter = 90 best fitness = 0.000\n",
      "Best Position: [14.72096179474869, -27.243223555620062]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, fitness, dim, min_bounds, max_bounds, seed):\n",
    "        self.rnd = random.Random(seed)\n",
    "        self.position = [(max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i] for i in range(dim)]\n",
    "        self.velocity = [(max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i] for i in range(dim)]\n",
    "        self.fitness = fitness(self.position)\n",
    "        self.best_part_pos = copy.copy(self.position)\n",
    "        self.best_part_fitnessVal = self.fitness\n",
    "\n",
    "def exponential_fitness(a):\n",
    "    # Standard exponential function: f(x) = e^(-x^2)\n",
    "    r = 4\n",
    "    return r * math.exp(-sum(x ** 2 for x in a))\n",
    "\n",
    "def psoexpo1(fitness, max_iter, n, dim, min_bounds, max_bounds, w_max=1, alpha=0.01):\n",
    "    # w is now dynamic and will be calculated per iteration\n",
    "    c1 = 1.49445\n",
    "    c2 = 1.49445\n",
    "    rnd = random.Random(0)\n",
    "    \n",
    "    swarm = [Particle(fitness, dim, min_bounds, max_bounds, i) for i in range(n)]\n",
    "    best_swarm_pos = [0.0 for _ in range(dim)]\n",
    "    best_swarm_fitnessVal = sys.float_info.max\n",
    "    w_values = []\n",
    "    for i in range(n):\n",
    "        if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "            best_swarm_fitnessVal = swarm[i].fitness\n",
    "            best_swarm_pos = copy.copy(swarm[i].position)\n",
    "    \n",
    "    Iter = 0\n",
    "    results = []  # Store results for writing to Excel\n",
    "    \n",
    "    while Iter < max_iter:\n",
    "        w = w_max * math.exp(-alpha * Iter)\n",
    "        w_values.append(w)\n",
    "        if Iter % 10 == 0 and Iter > 1:\n",
    "            print(f\"Iter = {Iter} best fitness = {best_swarm_fitnessVal:.3f}\")\n",
    "            results.append((Iter, best_swarm_fitnessVal))\n",
    "        \n",
    "        for i in range(n):\n",
    "            for k in range(dim):\n",
    "                r1 = rnd.random()\n",
    "                r2 = rnd.random()\n",
    "                swarm[i].velocity[k] = (\n",
    "                    (w * swarm[i].velocity[k]) +\n",
    "                    (c1 * r1 * (swarm[i].best_part_pos[k] - swarm[i].position[k])) +\n",
    "                    (c2 * r2 * (best_swarm_pos[k] - swarm[i].position[k]))\n",
    "                )\n",
    "                # Ensure the velocity stays within bounds\n",
    "                swarm[i].velocity[k] = max(min_bounds[k], min(swarm[i].velocity[k], max_bounds[k]))\n",
    "                \n",
    "            swarm[i].position = [swarm[i].position[k] + swarm[i].velocity[k] for k in range(dim)]\n",
    "            \n",
    "            swarm[i].fitness = fitness(swarm[i].position)\n",
    "            if swarm[i].fitness < swarm[i].best_part_fitnessVal:\n",
    "                swarm[i].best_part_fitnessVal = swarm[i].fitness\n",
    "                swarm[i].best_part_pos = copy.copy(swarm[i].position)\n",
    "            if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "                best_swarm_fitnessVal = swarm[i].fitness\n",
    "                best_swarm_pos = copy.copy(swarm[i].position)\n",
    "        Iter += 1\n",
    "    \n",
    "    return best_swarm_pos, w_values\n",
    "\n",
    "# Example usage (you need to define your own fitness function, dimension, bounds, etc.)\n",
    "best_position, w_values = psoexpo1(exponential_fitness, 100, 30, 2, [-10, -10], [10, 10])\n",
    "print(\"Best Position:\", best_position)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PSO using exponential map(w_max and w_min)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, fitness, dim, min_bounds, max_bounds, seed):\n",
    "        self.rnd = random.Random(seed)\n",
    "        self.position = [(max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i] for i in range(dim)]\n",
    "        self.velocity = [(max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i] for i in range(dim)]\n",
    "        self.fitness = fitness(self.position)  # Calculate fitness\n",
    "        self.best_part_pos = copy.copy(self.position)\n",
    "        self.best_part_fitnessVal = self.fitness\n",
    "\n",
    "def psoexpo2(fitness, max_iter, n, dim, min_bounds, max_bounds, w_max=0.9, w_min=0.4, alpha=0.01):\n",
    "    rnd = random.Random(0)\n",
    "    swarm = [Particle(fitness, dim, min_bounds, max_bounds, i) for i in range(n)]\n",
    "    best_swarm_pos = [0.0 for _ in range(dim)]\n",
    "    best_swarm_fitnessVal = sys.float_info.max\n",
    "    w_values = []\n",
    "    for i in range(n):\n",
    "        if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "            best_swarm_fitnessVal = swarm[i].fitness\n",
    "            best_swarm_pos = copy.copy(swarm[i].position)\n",
    "    \n",
    "    Iter = 0\n",
    "    results = []  # For storing results to possibly write to an Excel file later\n",
    "    \n",
    "    while Iter < max_iter:\n",
    "        # Adjust w dynamically between w_max and w_min\n",
    "        w = w_min + (w_max - w_min) * math.exp(-alpha * Iter)\n",
    "        w_values.append(w)\n",
    "        \n",
    "        if Iter % 10 == 0 and Iter > 1:\n",
    "            print(f\"Iter = {Iter} best fitness = {best_swarm_fitnessVal:.3f}\")\n",
    "            results.append((Iter, best_swarm_fitnessVal))\n",
    "        \n",
    "        for i in range(n):\n",
    "            for k in range(dim):\n",
    "                r1 = rnd.random()\n",
    "                r2 = rnd.random()\n",
    "                swarm[i].velocity[k] = (\n",
    "                    w * swarm[i].velocity[k] +\n",
    "                    (1.49445 * r1 * (swarm[i].best_part_pos[k] - swarm[i].position[k])) +\n",
    "                    (1.49445 * r2 * (best_swarm_pos[k] - swarm[i].position[k]))\n",
    "                )\n",
    "                # Clamp velocity within bounds\n",
    "                swarm[i].velocity[k] = max(min_bounds[k], min(swarm[i].velocity[k], max_bounds[k]))\n",
    "                \n",
    "            swarm[i].position = [swarm[i].position[k] + swarm[i].velocity[k] for k in range(dim)]\n",
    "            swarm[i].fitness = fitness(swarm[i].position)\n",
    "            if swarm[i].fitness < swarm[i].best_part_fitnessVal:\n",
    "                swarm[i].best_part_fitnessVal = swarm[i].fitness\n",
    "                swarm[i].best_part_pos = copy.copy(swarm[i].position)\n",
    "            if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "                best_swarm_fitnessVal = swarm[i].fitness\n",
    "                best_swarm_pos = copy.copy(swarm[i].position)\n",
    "        Iter += 1\n",
    "    \n",
    "    # Optional: Save results to a DataFrame and then to Excel\n",
    "    # df_results = pd.DataFrame(results, columns=['Iteration', 'Best Fitness'])\n",
    "    # df_results.to_excel('PSO_Results.xlsx', index=False)\n",
    "    \n",
    "    return best_swarm_pos, w_values\n",
    "\n",
    "# Example usage\n",
    "# Define your own fitness function, dimension, bounds, etc.\n",
    "# best_position = pso(your_fitness_function, 100, 30, 2, [-10, -10], [10, 10])\n",
    "# print(\"Best Position:\", best_position)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PSO using Exponential Map( updating c1 and c2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, fitness, dim, min_bounds, max_bounds, seed):\n",
    "        self.rnd = random.Random(seed)\n",
    "        self.position = [(max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i] for i in range(dim)]\n",
    "        self.velocity = [(max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i] for i in range(dim)]\n",
    "        self.fitness = fitness(self.position)  # Calculate fitness\n",
    "        self.best_part_pos = copy.copy(self.position)\n",
    "        self.best_part_fitnessVal = self.fitness\n",
    "\n",
    "def psoexpo3(fitness, max_iter, n, dim, min_bounds, max_bounds, w_max=0.729, c1_initial=1.49445, c2_initial=1.49445, alpha_c=0.02):\n",
    "    # Initialize random number generator\n",
    "    rnd = random.Random(0)\n",
    "    \n",
    "    # Initialize swarm\n",
    "    swarm = [Particle(fitness, dim, min_bounds, max_bounds, i) for i in range(n)]\n",
    "    \n",
    "    # Initialize best swarm position and fitness\n",
    "    best_swarm_pos = [0.0 for _ in range(dim)]\n",
    "    best_swarm_fitnessVal = sys.float_info.max\n",
    "    \n",
    "    # Initialize inertia weight\n",
    "    w_values = []\n",
    "    w = w_max\n",
    "    \n",
    "    # Initialize acceleration coefficients\n",
    "    c1_values = []\n",
    "    c2_values = []\n",
    "    c1 = c1_initial\n",
    "    c2 = c2_initial\n",
    "    \n",
    "    # Store results for plotting\n",
    "    results = []\n",
    "    \n",
    "    # Main PSO loop\n",
    "    for Iter in range(max_iter):\n",
    "        # Update inertia weight (optional)\n",
    "        w_values.append(w)\n",
    "        \n",
    "        # Update acceleration coefficients using exponential decay\n",
    "        c1 = max(c1_initial * math.exp(-alpha_c * Iter), 0.1)  # Lower bound of 0.1 for c1\n",
    "        c2 = max(c2_initial * math.exp(-alpha_c * Iter), 0.1)  # Lower bound of 0.1 for c2\n",
    "        c1_values.append(c1)\n",
    "        c2_values.append(c2)\n",
    "        \n",
    "        # Update global best position and fitness\n",
    "        for i in range(n):\n",
    "            if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "                best_swarm_fitnessVal = swarm[i].fitness\n",
    "                best_swarm_pos = copy.copy(swarm[i].position)\n",
    "        \n",
    "        # Update each particle's position and velocity\n",
    "        for i in range(n):\n",
    "            for k in range(dim):\n",
    "                r1 = rnd.random()\n",
    "                r2 = rnd.random()\n",
    "                swarm[i].velocity[k] = (\n",
    "                    (w * swarm[i].velocity[k]) +\n",
    "                    (c1 * r1 * (swarm[i].best_part_pos[k] - swarm[i].position[k])) +\n",
    "                    (c2 * r2 * (best_swarm_pos[k] - swarm[i].position[k]))\n",
    "                )\n",
    "                # Ensure velocity stays within bounds\n",
    "                swarm[i].velocity[k] = max(min_bounds[k], min(swarm[i].velocity[k], max_bounds[k]))\n",
    "                \n",
    "            # Update particle's position\n",
    "            swarm[i].position = [swarm[i].position[k] + swarm[i].velocity[k] for k in range(dim)]\n",
    "            \n",
    "            # Update particle's fitness\n",
    "            swarm[i].fitness = fitness(swarm[i].position)\n",
    "            \n",
    "            # Update particle's best-known position and fitness\n",
    "            if swarm[i].fitness < swarm[i].best_part_fitnessVal:\n",
    "                swarm[i].best_part_fitnessVal = swarm[i].fitness\n",
    "                swarm[i].best_part_pos = copy.copy(swarm[i].position)\n",
    "            \n",
    "            # Update global best position and fitness\n",
    "            if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "                best_swarm_fitnessVal = swarm[i].fitness\n",
    "                best_swarm_pos = copy.copy(swarm[i].position)\n",
    "        \n",
    "        # Store results for plotting (optional)\n",
    "        if Iter % 10 == 0 and Iter > 1:\n",
    "            results.append((Iter, best_swarm_fitnessVal))\n",
    "    \n",
    "    # Return best swarm position and acceleration coefficient values\n",
    "    return best_swarm_pos,w_values, c1_values, c2_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PSO Using Exponential ( r1 and r2 decay )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, fitness, dim, min_bounds, max_bounds, seed):\n",
    "        self.rnd = random.Random(seed)\n",
    "        self.position = [0.0 for _ in range(dim)]\n",
    "        self.velocity = [0.0 for _ in range(dim)]\n",
    "        self.best_part_pos = [0.0 for _ in range(dim)]\n",
    "        \n",
    "        for i in range(dim):\n",
    "            self.position[i] = (max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i]\n",
    "            self.velocity[i] = (max_bounds[i] - min_bounds[i]) * self.rnd.random() + min_bounds[i]\n",
    "        \n",
    "        self.fitness = fitness(self.position)\n",
    "        self.best_part_pos = copy.copy(self.position)\n",
    "        self.best_part_fitnessVal = self.fitness\n",
    "\n",
    "def exponential_map(value, scale=1.0):\n",
    "    return -math.log(1.0 - value) / scale\n",
    "\n",
    "def psor1(fitness, max_iter, n, dim, min_bounds, max_bounds):\n",
    "    w = 0.729\n",
    "    c1 = 1.49445\n",
    "    c2 = 1.49445\n",
    "    rnd = random.Random(0)\n",
    "    \n",
    "    swarm = [Particle(fitness, dim, min_bounds, max_bounds, i) for i in range(n)]\n",
    "    \n",
    "    best_swarm_pos = [0.0 for _ in range(dim)]\n",
    "    best_swarm_fitnessVal = sys.float_info.max\n",
    "    w_values = []\n",
    "    for i in range(n):\n",
    "        if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "            best_swarm_fitnessVal = swarm[i].fitness\n",
    "            best_swarm_pos = copy.copy(swarm[i].position)\n",
    "    \n",
    "    Iter = 0\n",
    "    results = []  # Store results for writing to Excel\n",
    "    \n",
    "    while Iter < max_iter:\n",
    "        if Iter % 10 == 0 and Iter > 1:\n",
    "            print(\"Iter = \" + str(Iter) + \" best fitness = %.3f\" % best_swarm_fitnessVal)\n",
    "            results.append((Iter, best_swarm_fitnessVal))\n",
    "            w_values.append(w)\n",
    "        for i in range(n):\n",
    "            for k in range(dim):\n",
    "                r1 = exponential_map(rnd.random())\n",
    "                r2 = exponential_map(rnd.random())\n",
    "                swarm[i].velocity[k] = (\n",
    "                    (w * swarm[i].velocity[k]) +\n",
    "                    (c1 * r1 * (swarm[i].best_part_pos[k] - swarm[i].position[k])) +\n",
    "                    (c2 * r2 *(best_swarm_pos[k] - swarm[i].position[k]))\n",
    "                )\n",
    "                if swarm[i].velocity[k] < min_bounds[k]:\n",
    "                    swarm[i].velocity[k] = min_bounds[k]\n",
    "                elif swarm[i].velocity[k] > max_bounds[k]:\n",
    "                    swarm[i].velocity[k] = max_bounds[k]\n",
    "            for k in range(dim):\n",
    "                swarm[i].position[k] += swarm[i].velocity[k]\n",
    "            swarm[i].fitness = fitness(swarm[i].position)\n",
    "            if swarm[i].fitness < swarm[i].best_part_fitnessVal:\n",
    "                swarm[i].best_part_fitnessVal = swarm[i].fitness\n",
    "                swarm[i].best_part_pos = copy.copy(swarm[i].position)\n",
    "            if swarm[i].fitness < best_swarm_fitnessVal:\n",
    "                best_swarm_fitnessVal = swarm[i].fitness\n",
    "                best_swarm_pos = copy.copy(swarm[i].position)\n",
    "        Iter += 1\n",
    "    \n",
    "    return best_swarm_pos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grey Wolf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def grey_wolf_optimization(obj_func, num_dimensions, population_size, max_iterations, lb, ub):\n",
    "    # Initialization\n",
    "    alpha_position = np.zeros(num_dimensions)\n",
    "    beta_position = np.zeros(num_dimensions)\n",
    "    delta_position = np.zeros(num_dimensions)\n",
    "\n",
    "    alpha_score = float('inf')\n",
    "    beta_score = float('inf')\n",
    "    delta_score = float('inf')\n",
    "\n",
    "    # Initialize the population\n",
    "    positions = np.random.uniform(low=lb, high=ub, size=(population_size, num_dimensions))\n",
    "\n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        \n",
    "        for i in range(population_size):\n",
    "            # Evaluate fitness\n",
    "            fitness = obj_func(positions[i, :])\n",
    "\n",
    "            # Update alpha, beta, and delta\n",
    "            if fitness < alpha_score:\n",
    "                delta_score = beta_score\n",
    "                delta_position = beta_position.copy()\n",
    "                beta_score = alpha_score\n",
    "                beta_position = alpha_position.copy()\n",
    "                alpha_score = fitness\n",
    "                alpha_position = positions[i, :].copy()\n",
    "            elif fitness < beta_score:\n",
    "                delta_score = beta_score\n",
    "                delta_position = beta_position.copy()\n",
    "                beta_score = fitness\n",
    "                beta_position = positions[i, :].copy()\n",
    "            elif fitness < delta_score:\n",
    "                delta_score = fitness\n",
    "                delta_position = positions[i, :].copy()\n",
    "\n",
    "        a = 2 - 2 * iteration / max_iterations  # a decreases linearly from 2 to 0\n",
    "\n",
    "        # Update positions of the wolves\n",
    "        for i in range(population_size):\n",
    "            r1 = np.random.random(num_dimensions)  # Random vectors\n",
    "            r2 = np.random.random(num_dimensions)\n",
    "            A1 = 2 * a * r1 - a  # Eq. (3.3)\n",
    "            C1 = 2 * r2  # Eq. (3.4)\n",
    "\n",
    "            # Update alpha position\n",
    "            D_alpha = abs(C1 * alpha_position - positions[i, :])  # Eq. (3.5)-part 1\n",
    "            X1 = alpha_position - A1 * D_alpha  # Eq. (3.6)-part 1\n",
    "\n",
    "            r1 = np.random.random(num_dimensions)\n",
    "            r2 = np.random.random(num_dimensions)\n",
    "            A2 = 2 * a * r1 - a  # Eq. (3.3)\n",
    "            C2 = 2 * r2  # Eq. (3.4)\n",
    "\n",
    "            # Update beta position\n",
    "            D_beta = abs(C2 * beta_position - positions[i, :])  # Eq. (3.5)-part 2\n",
    "            X2 = beta_position - A2 * D_beta  # Eq. (3.6)-part 2\n",
    "\n",
    "            r1 = np.random.random(num_dimensions)\n",
    "            r2 = np.random.random(num_dimensions)\n",
    "            A3 = 2 * a * r1 - a  # Eq. (3.3)\n",
    "            C3 = 2 * r2  # Eq. (3.4)\n",
    "\n",
    "            # Update delta position\n",
    "            D_delta = abs(C3 * delta_position - positions[i, :])  # Eq. (3.5)-part 3\n",
    "            X3 = delta_position - A3 * D_delta  # Eq. (3.5)-part 3\n",
    "\n",
    "            # Update the position of the current wolf\n",
    "            positions[i, :] = (X1 + X2 + X3) / 3.0\n",
    "\n",
    "            # Clip the positions to stay within the search space\n",
    "            positions[i, :] = np.clip(positions[i, :], lb, ub)\n",
    "\n",
    "    # Return the best solution found\n",
    "    return alpha_position, alpha_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOolxQWs-VbB"
   },
   "source": [
    "### **7.1. Decision Tree Classifier**\n",
    " Decision trees are widely used models for classification and regression tasks. Essentially, they learn a hierarchy of if/else questions, leading to a decision. Learning a decision tree means learning the sequence of if/else questions that gets us to the true answer most quickly.\n",
    " \n",
    "In the machine learning setting, these questions are called tests (not to be confused with the test set, which is the data we use to test to see how generalizable our model is). To build a tree, the algorithm searches over all possible tests and finds the one that is most informative about the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "1kzsjtudy-0w",
    "outputId": "80b84eba-eeb1-48d1-d95a-412b7cfb4c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# instantiate the model \n",
    "tree = DecisionTreeClassifier(max_depth = 5)\n",
    "# fit the model \n",
    "tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpPk7O-MrTZi"
   },
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "y_test_tree = tree.predict(X_test)\n",
    "y_train_tree = tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLn-_qOuS_9Y"
   },
   "source": [
    "**Performance Evaluation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "X4wDTnFZrz3q",
    "outputId": "a8bf5873-8185-4f18-e0f0-87717975e5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Accuracy on training Data: 0.810\n",
      "Decision Tree: Accuracy on test Data: 0.817\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy of the model performance\n",
    "acc_train_tree = accuracy_score(y_train,y_train_tree)\n",
    "acc_test_tree = accuracy_score(y_test,y_test_tree)\n",
    "\n",
    "print(\"Decision Tree: Accuracy on training Data: {:.3f}\".format(acc_train_tree))\n",
    "print(\"Decision Tree: Accuracy on test Data: {:.3f}\".format(acc_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Precision on training Data: 0.960\n",
      "Decision Tree: Recall on training Data: 0.652\n",
      "Decision: F1-score on training Data: 0.776\n",
      "Decision Tree: Precision on test Data: 0.958\n",
      "Decision Tree: Recall on test Data: 0.645\n",
      "Decision: F1-score on test Data: 0.771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have predicted values for both training and test sets (y_train_forest, y_test_forest)\n",
    "\n",
    "# Precision, Recall, and F1-score on training data\n",
    "precision_train_forest = precision_score(y_train, y_train_tree, average='binary')  # Use average='micro' for multiclass\n",
    "recall_train_forest = recall_score(y_train, y_train_tree, average='binary')\n",
    "f1_train_forest = f1_score(y_train, y_train_tree, average='binary')\n",
    "\n",
    "print(\"Decision Tree: Precision on training Data: {:.3f}\".format(precision_train_forest))\n",
    "print(\"Decision Tree: Recall on training Data: {:.3f}\".format(recall_train_forest))\n",
    "print(\"Decision: F1-score on training Data: {:.3f}\".format(f1_train_forest))\n",
    "\n",
    "\n",
    "\n",
    "precision_test_forest = precision_score(y_test, y_test_tree, average='binary')  # Use average='micro' for multiclass\n",
    "recall_test_forest = recall_score(y_test, y_test_tree, average='binary')\n",
    "f1_test_forest = f1_score(y_test, y_test_tree, average='binary')\n",
    "\n",
    "print(\"Decision Tree: Precision on test Data: {:.3f}\".format(precision_test_forest))\n",
    "print(\"Decision Tree: Recall on test Data: {:.3f}\".format(recall_test_forest))\n",
    "print(\"Decision: F1-score on test Data: {:.3f}\".format(f1_test_forest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective function(Decision Tree)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "LITrJdVGWwTl",
    "outputId": "363e0abd-28df-4703-b784-5f5af37cab30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def decision_tree_fitness(position):\n",
    "    # Convert position to integer values for max_depth and min_samples_split\n",
    "    max_depth = int(position[0])\n",
    "    min_samples_split = int(position[1])\n",
    "    #min_samples_leaf = int(position[2])\n",
    "    #max_features = int(position[3])\n",
    "\n",
    "    # Create a Decision Tree Classifier with the given parameters\n",
    "    dt_classifier = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split,  random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = dt_classifier.predict(X_train)\n",
    "\n",
    "    # Calculate the accuracy score as the fitness value\n",
    "    fitness_value = accuracy_score(y_train, y_pred)\n",
    "    \n",
    "    return fitness_value\n",
    "    \n",
    "decision_tree_fitness([125,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XpC9PAn5RTfY"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XKvXxr9RSxl"
   },
   "source": [
    "**DECISION TREE USING GWO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [79]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m upper_bounds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Run the PSO algorithm with the decision_tree_fitness function\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m best_position, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgrey_wolf_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree_fitness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_bounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Store iteration number and corresponding fitness for plotting\u001b[39;00m\n\u001b[0;32m     24\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36mgrey_wolf_optimization\u001b[1;34m(obj_func, num_dimensions, population_size, max_iterations, lb, ub)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_iterations \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(population_size):\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;66;03m# Evaluate fitness\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m         fitness \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# Update alpha, beta, and delta\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fitness \u001b[38;5;241m<\u001b[39m alpha_score:\n",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36mdecision_tree_fitness\u001b[1;34m(position)\u001b[0m\n\u001b[0;32m     13\u001b[0m dt_classifier \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39mmin_samples_split,  random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Train the classifier on the training data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mdt_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m dt_classifier\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the PSO algorithm in a loop 5 times\n",
    "import random\n",
    "\n",
    "# Define the dimensionality of the problem (number of parameters to optimize)\n",
    "dimensions = 3  # In the given decision_tree_fitness function, you have 2 parameters: max_depth and min_samples_split\n",
    "\n",
    "# Set the number of particles in the swarm\n",
    "population_size = 50\n",
    "iteration_points = []\n",
    "fitness_points = [] \n",
    "# Set the maximum number of iterations\n",
    "max_iter = 100\n",
    "for _ in range(1):\n",
    "    # Assign random and non-uniform values to lower and upper bounds\n",
    "    #lower_bounds = [random.randint(8, 18), random.randint(1, 5)]\n",
    "    #upper_bounds = [random.randint(68, 78), random.randint(54, 74)]\n",
    "    lower_bounds = [125,2,1]\n",
    "    upper_bounds = [200,10,10]\n",
    "    # Run the PSO algorithm with the decision_tree_fitness function\n",
    "    best_position,_ = grey_wolf_optimization(decision_tree_fitness, dimensions, population_size,max_iter, lower_bounds, upper_bounds)\n",
    "\n",
    "    \n",
    "    # Store iteration number and corresponding fitness for plotting\n",
    "    iterations = list(range(1, max_iter + 1))\n",
    "    fitness_values = [decision_tree_fitness(best_position) for _ in iterations]\n",
    "\n",
    "    iteration_points.extend(iterations)\n",
    "    fitness_points.extend(fitness_values)\n",
    "\n",
    "    # Print the result of the 100th iteration\n",
    "    print(\"Result of the 100th iteration:\", best_position)\n",
    "    print('Lower Bounds:', lower_bounds)\n",
    "    print('Upper Bounds:', upper_bounds)\n",
    "\n",
    "    # Calculate and print the best fitness after the 100th iteration\n",
    "    best_fitness = decision_tree_fitness(best_position)\n",
    "    \n",
    "    print(\"Best Fitness after the 100th iteration:\", best_fitness,_)\n",
    "    print(\"-\" * 40)  # Separator for better visibility\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(iteration_points, fitness_points, marker='o', color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Fitness')\n",
    "plt.title('PSO Optimization Results')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**DECISION TREE WITH PSO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 10 best fitness = 0.826\n",
      "Iter = 20 best fitness = 0.822\n",
      "Iter = 30 best fitness = 0.822\n",
      "Iter = 40 best fitness = 0.822\n",
      "Iter = 50 best fitness = 0.822\n",
      "Iter = 60 best fitness = 0.822\n",
      "Iter = 70 best fitness = 0.822\n",
      "Iter = 80 best fitness = 0.822\n",
      "Iter = 90 best fitness = 0.822\n",
      "Iter = 100 best fitness = 0.822\n",
      "Iter = 110 best fitness = 0.822\n",
      "Iter = 120 best fitness = 0.822\n",
      "Iter = 130 best fitness = 0.822\n",
      "Iter = 140 best fitness = 0.822\n",
      "Iter = 150 best fitness = 0.818\n",
      "Iter = 160 best fitness = 0.818\n",
      "Iter = 170 best fitness = 0.818\n",
      "Iter = 180 best fitness = 0.818\n",
      "Iter = 190 best fitness = 0.812\n",
      "Result of the 200th iteration: [1246.313878677638, 987.1092280594424]\n",
      "Lower Bounds: [4, 1]\n",
      "Upper Bounds: [100, 89]\n",
      "Best Fitness after the 100th iteration: 0.8125\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the PSO algorithm in a loop 5 times\n",
    "import random\n",
    "\n",
    "# Define the dimensionality of the problem (number of parameters to optimize)\n",
    "dimensions = 2  # In the given decision_tree_fitness function, you have 2 parameters: max_depth and min_samples_split\n",
    "\n",
    "# Set the number of particles in the swarm\n",
    "n_particles = 20\n",
    "iteration_points = []\n",
    "fitness_points = []\n",
    "# Set the maximum number of iterations\n",
    "max_iter = 200\n",
    "for _ in range(1):\n",
    "    # Assign random and non-uniform values to lower and upper bounds\n",
    "    #lower_bounds = [random.randint(8, 18), random.randint(1, 5)]\n",
    "    #upper_bounds = [random.randint(68, 78), random.randint(54, 74)]\n",
    "    lower_bounds = [4,1]\n",
    "    upper_bounds = [100,89]\n",
    "    # Run the PSO algorithm with the decision_tree_fitness function\n",
    "    best_position,w_values= psoexpo1(decision_tree_fitness, max_iter, n_particles, dimensions, lower_bounds, upper_bounds)\n",
    "    \n",
    "    \n",
    "    # Store iteration number and corresponding fitness for plotting\n",
    "    iterations = list(range(1, max_iter + 1))\n",
    "    fitness_values = [decision_tree_fitness(best_position) for _ in iterations]\n",
    "\n",
    "    iteration_points.extend(iterations)\n",
    "    fitness_points.extend(fitness_values)\n",
    "\n",
    "    # Print the result of the 100th iteration\n",
    "    print(\"Result of the 200th iteration:\", best_position)\n",
    "    print('Lower Bounds:', lower_bounds)\n",
    "    print('Upper Bounds:', upper_bounds)\n",
    "\n",
    "    # Calculate and print the best fitness after the 100th iteration\n",
    "    best_fitness = decision_tree_fitness(best_position)\n",
    "    print(\"Best Fitness after the 100th iteration:\", best_fitness)\n",
    "    print(\"-\" * 40)  # Separator for better visibility\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(max_iter), w_values, label='Inertia Weight (w) over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Inertia Weight (w)')\n",
    "plt.title('Inertia Weight Decay')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(max_iter), c1_values, label='C1 over Iterations')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('(c1)')\n",
    "# plt.title('C1 Decay')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(max_iter), c2_values, label='C2 over Iterations')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('(c2)')\n",
    "# plt.title('c2 decay')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# Create a scatter plot\n",
    "plt.scatter(iteration_points, fitness_points, marker='o', color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Fitness')\n",
    "plt.title('PSO Optimization Results')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot\n",
    "plt.scatter(iteration_points, fitness_points, marker='o', color='yellow', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Fitness')\n",
    "plt.title('PSO Optimization Results')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LuDTMcmb-n5x"
   },
   "source": [
    "### **7.2. Random Forest Classifier**\n",
    "Random forests for regression and classification are currently among the most widely used machine learning methods.A random forest is essentially a collection of decision trees, where each tree is slightly different from the others. The idea behind random forests is that each tree might do a relatively good job of predicting, but will likely overfit on part of the data.\n",
    "\n",
    "If we build many trees, all of which work well and overfit in different ways, we can reduce the amount of overfitting by averaging their results. To build a random forest model, you need to decide on the number of trees to build (the n_estimators parameter of RandomForestRegressor or RandomForestClassifier). They are very powerful, often work well without heavy tuning of the parameters, and dont require scaling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "2fmB9rPSsR6y",
    "outputId": "27ddebf4-bee1-4eec-eb4e-995d4cdc08b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate the model\n",
    "forest = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "# fit the model \n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1Qck-wrsabB"
   },
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "y_test_forest = forest.predict(X_test)\n",
    "y_train_forest = forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8TybBPHT1ao"
   },
   "source": [
    "**Performance Evaluation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Oguf-37tsboO",
    "outputId": "34386ec6-a7f0-4185-b3c0-a40de3239fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest: Accuracy on training Data: 0.813\n",
      "Random forest: Accuracy on test Data: 0.811\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy of the model performance\n",
    "acc_train_forest = accuracy_score(y_train,y_train_forest)\n",
    "acc_test_forest = accuracy_score(y_test,y_test_forest)\n",
    "\n",
    "print(\"Random forest: Accuracy on training Data: {:.3f}\".format(acc_train_forest))\n",
    "print(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc_test_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "m9GZGxvZ9jnB",
    "outputId": "465186a8-d622-4427-c148-9dff349b40eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Precision on training Data: 0.983\n",
      "Decision Tree: Recall on training Data: 0.636\n",
      "Decision: F1-score on training Data: 0.772\n",
      "Decision Tree: Precision on test Data: 0.985\n",
      "Decision Tree: Recall on test Data: 0.635\n",
      "Decision: F1-score on test Data: 0.772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have predicted values for both training and test sets (y_train_forest, y_test_forest)\n",
    "\n",
    "# Precision, Recall, and F1-score on training data\n",
    "precision_train_forest = precision_score(y_train, y_train_forest, average='binary')  # Use average='micro' for multiclass\n",
    "recall_train_forest = recall_score(y_train, y_train_forest, average='binary')\n",
    "f1_train_forest = f1_score(y_train, y_train_forest, average='binary')\n",
    "\n",
    "print(\"Decision Tree: Precision on training Data: {:.3f}\".format(precision_train_forest))\n",
    "print(\"Decision Tree: Recall on training Data: {:.3f}\".format(recall_train_forest))\n",
    "print(\"Decision: F1-score on training Data: {:.3f}\".format(f1_train_forest))\n",
    "\n",
    "\n",
    "\n",
    "precision_test_forest = precision_score(y_test, y_test_forest, average='binary')  # Use average='micro' for multiclass\n",
    "recall_test_forest = recall_score(y_test, y_test_forest, average='binary')\n",
    "f1_test_forest = f1_score(y_test, y_test_forest, average='binary')\n",
    "\n",
    "print(\"Decision Tree: Precision on test Data: {:.3f}\".format(precision_test_forest))\n",
    "print(\"Decision Tree: Recall on test Data: {:.3f}\".format(recall_test_forest))\n",
    "print(\"Decision: F1-score on test Data: {:.3f}\".format(f1_test_forest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6U_BEF8W-FS"
   },
   "source": [
    "**Storing the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNf4EXHUW-FU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def fitness_random_forest(params):\n",
    "    \n",
    "    max_depth, n_estimators = params  # You can adapt this to your specific hyperparameters\n",
    "    n_estimators = int(n_estimators)\n",
    "    # Create a Random Forest Classifier with the given parameters\n",
    "    forest = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=0)\n",
    "\n",
    "    # Evaluate the classifier using cross-validation\n",
    "    scores = cross_val_score(forest, X_train, y_train, cv=5, scoring='accuracy')  # You can adjust the cross-validation strategy and scoring method\n",
    "\n",
    "    # Calculate the mean accuracy from cross-validation\n",
    "    mean_accuracy = scores.mean()\n",
    "\n",
    "    # Since PSO tries to minimize the fitness function, return the negative accuracy (to maximize accuracy)\n",
    "    return -mean_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 10 best fitness = -0.861\n",
      "Iter = 20 best fitness = -0.861\n",
      "Iter = 30 best fitness = -0.861\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [86]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m ub \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m20\u001b[39m]\n\u001b[0;32m      5\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 7\u001b[0m best_hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[43mpso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitness_random_forest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mub\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36mpso\u001b[1;34m(fitness, max_iter, n, dim, min_bounds, max_bounds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dim):\n\u001b[0;32m     60\u001b[0m     swarm[i]\u001b[38;5;241m.\u001b[39mposition[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m swarm[i]\u001b[38;5;241m.\u001b[39mvelocity[k]\n\u001b[1;32m---> 61\u001b[0m swarm[i]\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mswarm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m swarm[i]\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m<\u001b[39m swarm[i]\u001b[38;5;241m.\u001b[39mbest_part_fitnessVal:\n\u001b[0;32m     63\u001b[0m     swarm[i]\u001b[38;5;241m.\u001b[39mbest_part_fitnessVal \u001b[38;5;241m=\u001b[39m swarm[i]\u001b[38;5;241m.\u001b[39mfitness\n",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36mfitness_random_forest\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      8\u001b[0m forest \u001b[38;5;241m=\u001b[39m RandomForestClassifier(max_depth\u001b[38;5;241m=\u001b[39mmax_depth, n_estimators\u001b[38;5;241m=\u001b[39mn_estimators, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier using cross-validation\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# You can adjust the cross-validation strategy and scoring method\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the mean accuracy from cross-validation\u001b[39;00m\n\u001b[0;32m     14\u001b[0m mean_accuracy \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\sklearn\\tree\\_classes.py:214\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    212\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(y\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_):\n\u001b[1;32m--> 214\u001b[0m     classes_k, y_encoded[:, k] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mappend(classes_k)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\u001b[38;5;241m.\u001b[39mappend(classes_k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\numpy\\lib\\arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    270\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\numpy\\lib\\arraysetops.py:330\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    327\u001b[0m optional_indices \u001b[38;5;241m=\u001b[39m return_index \u001b[38;5;129;01mor\u001b[39;00m return_inverse\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_indices:\n\u001b[1;32m--> 330\u001b[0m     perm \u001b[38;5;241m=\u001b[39m \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmergesort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquicksort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_iter = 100  # Adjust the number of iterations as needed\n",
    "n = 10\n",
    "lb = [20, 1]  # Lower bounds for n_estimators and max_depth\n",
    "ub = [200, 20]\n",
    "dim = 2\n",
    "\n",
    "best_hyperparameters = pso(fitness_random_forest, max_iter, n, dim, lb, ub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJ_EW8QUC0bn"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "JSFAbsgnAxqv",
    "outputId": "2828ce2e-95ec-4dfd-e7dd-5d3da152ea09"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyuSg6w_A4pN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UlDx0rDXatCl"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "z2ndgKQbA64_",
    "outputId": "40ddef62-9dd4-4d55-b5ba-9932ba07a0b5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjBgfI64Xubd"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N0fsq4yEXubk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVuTty-KaS4c"
   },
   "source": [
    "### **7.4. XGBoost Classifier**\n",
    "XGBoost is one of the most popular machine learning algorithms these days. XGBoost stands for eXtreme Gradient Boosting. Regardless of the type of prediction task at hand; regression or classification. XGBoost is an implementation of gradient boosted decision trees designed for speed and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.0-py3-none-win_amd64.whl (99.7 MB)\n",
      "     ---------------------------------------- 99.7/99.7 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\python3.10\\lib\\site-packages (from xgboost) (1.22.4)\n",
      "Requirement already satisfied: scipy in c:\\python3.10\\lib\\site-packages (from xgboost) (1.7.3)Note: you may need to restart the kernel to use updated packages.\n",
      "Installing collected packages: xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully installed xgboost-2.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "id": "oIIQGzxgAREc",
    "outputId": "fc27da07-7071-4fbf-9d05-05e514ad9b3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.4, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost Classification model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# instantiate the model\n",
    "xgb = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "#fit the model\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fx9xbzfAUO-"
   },
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "y_test_xgb = xgb.predict(X_test)\n",
    "y_train_xgb = xgb.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pwoDNqDIaxB9"
   },
   "source": [
    "**Performance Evaluation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "x1NNeI-NaxCA",
    "outputId": "d021057e-e9bc-487d-b584-9fb2492305de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Accuracy on training Data: 0.867\n",
      "XGBoost : Accuracy on test Data: 0.860\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy of the model performance\n",
    "acc_train_xgb = accuracy_score(y_train,y_train_xgb)\n",
    "acc_test_xgb = accuracy_score(y_test,y_test_xgb)\n",
    "\n",
    "print(\"XGBoost: Accuracy on training Data: {:.3f}\".format(acc_train_xgb))\n",
    "print(\"XGBoost : Accuracy on test Data: {:.3f}\".format(acc_test_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_train_forest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m recall_train_xgb \u001b[38;5;241m=\u001b[39m recall_score(y_train, y_train_xgb, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m f1_train_xgb \u001b[38;5;241m=\u001b[39m f1_score(y_train, y_train_xgb, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree: Precision on training Data: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mprecision_train_forest\u001b[49m))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree: Recall on training Data: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(recall_train_forest))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision: F1-score on training Data: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f1_train_forest))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision_train_forest' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have predicted values for both training and test sets (y_train_forest, y_test_forest)\n",
    "\n",
    "# Precision, Recall, and F1-score on training data\n",
    "precision_train_xgb = precision_score(y_train, y_train_xgb, average='binary')  # Use average='micro' for multiclass\n",
    "recall_train_xgb = recall_score(y_train, y_train_xgb, average='binary')\n",
    "f1_train_xgb = f1_score(y_train, y_train_xgb, average='binary')\n",
    "\n",
    "print(\"Decision Tree: Precision on training Data: {:.3f}\".format(precision_train_forest))\n",
    "print(\"Decision Tree: Recall on training Data: {:.3f}\".format(recall_train_forest))\n",
    "print(\"Decision: F1-score on training Data: {:.3f}\".format(f1_train_forest))\n",
    "\n",
    "\n",
    "\n",
    "precision_test_xgb = precision_score(y_test, y_test_xgb, average='binary')  # Use average='micro' for multiclass\n",
    "recall_test_xgb = recall_score(y_test, y_test_xgb, average='binary')\n",
    "f1_test_xgb = f1_score(y_test, y_test_xgb, average='binary')\n",
    "\n",
    "print(\"Decision Tree: Precision on test Data: {:.3f}\".format(precision_test_forest))\n",
    "print(\"Decision Tree: Recall on test Data: {:.3f}\".format(recall_test_forest))\n",
    "print(\"Decision: F1-score on test Data: {:.3f}\".format(f1_test_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "def xgboost_fitness(position):\n",
    "    # Convert position t integer values for parameters\n",
    "    max_depth = int(position[0])\n",
    "    #learning_rate = position[1]\n",
    "    n_estimators = int(position[1])\n",
    "\n",
    "    # Create an XGBoost Classifier with the given parameters\n",
    "    xgb_classifier = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        #learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy score as the fitness value\n",
    "    fitness_value = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return fitness_value\n",
    "\n",
    "# Example usage of the PSO algorithm with the xgboost_fitness function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_g2HQNotaxCQ"
   },
   "source": [
    "**XG BOOST CLASSIFIER USING PSO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFNo8jskaxCS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "8Rca6ZpShnRN",
    "outputId": "1e8f7ecb-bbaa-4bd0-92dc-73a3ccf58fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 10 best fitness = 0.862\n",
      "Iter = 20 best fitness = 0.862\n",
      "Iter = 30 best fitness = 0.862\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m upper_bounds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m300\u001b[39m,\u001b[38;5;241m300\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Run the PSO algorithm with the decision_tree_fitness function\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m best_position \u001b[38;5;241m=\u001b[39m \u001b[43mpso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgboost_fitness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_particles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_bounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Store iteration number and corresponding fitness for plotting\u001b[39;00m\n\u001b[0;32m     24\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mpso\u001b[1;34m(fitness, max_iter, n, dim, min_bounds, max_bounds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dim):\n\u001b[0;32m     60\u001b[0m     swarm[i]\u001b[38;5;241m.\u001b[39mposition[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m swarm[i]\u001b[38;5;241m.\u001b[39mvelocity[k]\n\u001b[1;32m---> 61\u001b[0m swarm[i]\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mswarm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m swarm[i]\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m<\u001b[39m swarm[i]\u001b[38;5;241m.\u001b[39mbest_part_fitnessVal:\n\u001b[0;32m     63\u001b[0m     swarm[i]\u001b[38;5;241m.\u001b[39mbest_part_fitnessVal \u001b[38;5;241m=\u001b[39m swarm[i]\u001b[38;5;241m.\u001b[39mfitness\n",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36mxgboost_fitness\u001b[1;34m(position)\u001b[0m\n\u001b[0;32m     16\u001b[0m xgb_classifier \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     17\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m#learning_rate=learning_rate,\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[0;32m     20\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train the classifier on the training data\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mxgb_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\xgboost\\sklearn.py:1515\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1487\u001b[0m (\n\u001b[0;32m   1488\u001b[0m     model,\n\u001b[0;32m   1489\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1495\u001b[0m )\n\u001b[0;32m   1496\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1497\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1498\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1512\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1513\u001b[0m )\n\u001b[1;32m-> 1515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3.10\\lib\\site-packages\\xgboost\\core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2049\u001b[0m     _check_call(\n\u001b[1;32m-> 2050\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2053\u001b[0m     )\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2055\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the PSO algorithm in a loop 5 times\n",
    "import random\n",
    "\n",
    "# Define the dimensionality of the problem (number of parameters to optimize)\n",
    "dimensions = 2 # In the given decision_tree_fitness function, you have 2 parameters: max_depth and min_samples_split\n",
    "\n",
    "# Set the number of particles in the swarm\n",
    "n_particles = 20\n",
    "iteration_points = []\n",
    "fitness_points = []\n",
    "# Set the maximum number of iterations\n",
    "max_iter = 100\n",
    "for _ in range(1):\n",
    "    # Assign random and non-uniform values to lower and upper bounds\n",
    "    #lower_bounds = [random.randint(8, 18), random.randint(1, 5)]\n",
    "    #upper_bounds = [random.randint(68, 78), random.randint(54, 74)]\n",
    "    lower_bounds = [1,1]  # Minimum values for max_depth, learning_rate, and n_estimators\n",
    "    upper_bounds = [300,300]\n",
    "    # Run the PSO algorithm with the decision_tree_fitness function\n",
    "    best_position = pso(xgboost_fitness, max_iter, n_particles, dimensions, lower_bounds, upper_bounds)\n",
    "    \n",
    "    \n",
    "    # Store iteration number and corresponding fitness for plotting\n",
    "    iterations = list(range(1, max_iter + 1))\n",
    "    fitness_values = [xgboost_fitness(best_position) for _ in iterations]\n",
    "\n",
    "    iteration_points.extend(iterations)\n",
    "    fitness_points.extend(fitness_values)\n",
    "\n",
    "    # Print the result of the 100th iteration\n",
    "    print(\"Result of the 100th iteration:\", best_position)\n",
    "    print('Lower Bounds:', lower_bounds)\n",
    "    print('Upper Bounds:', upper_bounds)\n",
    "\n",
    "    # Calculate and print the best fitness after the 100th iteration\n",
    "    best_fitness = xgboost_fitness(best_position)\n",
    "    print(\"Best Fitness after the 100th iteration:\", best_fitness)\n",
    "    print(\"-\" * 40)  # Separator for better visibility\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(iteration_points, fitness_points, marker='o', color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Fitness')\n",
    "plt.title('PSO Optimization Results')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "FFet6_03sBtK",
    "outputId": "bfc5a82f-b08b-453b-cd31-da9ee824480f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1ONIVqSsXSP"
   },
   "source": [
    "**Define Fitness Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "TQa0u7vyj2Ml",
    "outputId": "73a8713c-683d-4a13-8619-5bd87adec0c8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YG5oxuvJsflM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqjgA0aCsflO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "plQeFh4fwB3a"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "VBnV71QowZ07",
    "outputId": "258bc8b4-ba81-4036-c558-11923a7b0b5e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Nlrfq-pwZ1G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qb2FHrUpwZ1P"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "1ofewcVHwZ1R",
    "outputId": "3f83bfc7-f885-49a7-ed88-816e05097eac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ToF9fRNSwZ1b"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZAc00sUwZ1d"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3vsRppPv3rs"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "RkOSzcfsv8Xl",
    "outputId": "82b2e437-b210-4b83-c3a0-dc9c5f65f9e0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "eKheGBiHwDfK",
    "outputId": "8ff038a3-9eea-472a-e1e7-ac6be45c9882"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5t9806vn601b"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCIIkZ7V3AFN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbrNHP0o3QrD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "id": "-ZEm_PS33QD-",
    "outputId": "a4195d7f-94ef-4bc7-a165-35ed2ed5493f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vy2egEdwkqZ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Phishing Website Detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
